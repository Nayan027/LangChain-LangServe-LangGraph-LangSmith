{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bb6f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_perplexity import ChatPerplexity\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatPerplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83124d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader #, PyPDFLoader, TextLoader\n",
    "\n",
    "doc_loader = WebBaseLoader(web_path=\"https://python.langchain.com/docs/introduction/\")\n",
    "docs = doc_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24236d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter #, TextSplitter, CharacterTextSplitter\n",
    "\n",
    "splitter_object = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunked_docs = splitter_object.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ac5fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cb46561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma #, Cassandra , FAISS\n",
    "\n",
    "vector_store = Chroma.from_documents(documents=chunked_docs, embedding=embedding_model)\n",
    "\n",
    "doc_retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafe386",
   "metadata": {},
   "source": [
    "### Query with similarity search\n",
    "query = \"Tell me about Python\"\n",
    "\n",
    "results = vector_store.similarity_search(query, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3bd22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f4f57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Answer to the user question from the document context only.\n",
    "In case of question being out of context reply with: Sorry, cannot answer irrelevant questions that are out of context.\n",
    "\n",
    "Make sure the answer is helpful to user's query.\n",
    "\\n\\n Context: {context}\\n\\n\n",
    "\n",
    "\\n\\n Question: {input}\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# user_input = \"what is langchain and what do you mean by langchain-ecosystem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1131ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "\n",
    "# user_input = \"what is langchain and what do you mean by langchain-ecosystem\"\n",
    "\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriever=doc_retriever, combine_docs_chain=document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"what is langchain and what do you mean by langchain-ecosystem\"\n",
    "\n",
    "retrieved_response = retrieval_chain.invoke({\"input\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3929db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**LangChain** is a framework that provides tools for building workflows powered by large language models (LLMs). It facilitates tasks such as integrating chat models, managing vector stores (databases that store vector embeddings), and handling documents in an efficient way to create applications leveraging LLMs[1][2][4].\\n\\nThe **LangChain ecosystem** refers to the collection of components, guides, integrations, and tools around LangChain that help users quickly accomplish common tasks. This includes conceptual guides explaining LangChain's key parts, how-tos on using LangChain-specific features like LangGraph, and integrations with various vector databases and embedding models to build end-to-end LLM-powered applications[Context].\\n\\nIn summary:\\n\\n| Term              | Description                                                                                         |\\n|-------------------|-------------------------------------------------------------------------------------------------|\\n| **LangChain**     | A framework for building applications with large language models, including vector store support. |\\n| **LangChain Ecosystem** | The set of guides, components, integrations, and tools that support and extend LangChain usage.      |\\n\\nThis ecosystem enables developers to efficiently work with chat models, vector stores, and other LangChain components to build LLM applications[Context][1][2].\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e75ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b27639c",
   "metadata": {},
   "source": [
    "KEY LEARNING NOTES FROM THIS SESSION:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e9814",
   "metadata": {},
   "source": [
    "### LangChain — create_stuff_documents_chain\n",
    "\n",
    "Purpose: ek document-combining chain banata hai jo multiple documents ko ek saath \"stuff\" (concatenate) karke LLM ko pass karta hai.\n",
    "\n",
    "Hard rule necessary everytime -- Prompt Requirement:\n",
    "Jab bhi create_stuff_documents_chain use karte ho, aapka ChatPromptTemplate dono placeholders {input} aur {context} contain karna chahiye.\n",
    "\n",
    "Placeholders (compulsory for ChatPromptTemplate):\n",
    "1. input → user ka question/sawal\n",
    "2. context → retrieved documents ka text (LLM ke liye source of truth)\n",
    "\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "llm = ChatOpenAI()       # LLM instance\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(       # Prompt with BOTH placeholders\n",
    "    \"You are a helpful assistant.\\n\"\n",
    "    \"Context: {context}\\n\\n\"\n",
    "    \"Question: {input}\\n\"\n",
    "    \"Answer:\"\n",
    ")\n",
    "\n",
    "\n",
    "doc_chain = create_stuff_documents_chain(llm, prompt)      # Create chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b52034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867e6638",
   "metadata": {},
   "source": [
    "### LangChain - Glue Logic: create_retrieval_chain\n",
    "\n",
    "Jab aap create_retrieval_chain(retriever, doc_chain) banate ho → LangChain internally ek mapping function banata hai jo retriever output ko \"context\" key me daalta hai.\n",
    "\n",
    "Aapko kabhi manually {context} pass nahi karna padta jis trh {input} ko pass krna pdta hai while invoking.\n",
    "\n",
    "retrieval_chain internally retriever ke docs ko \"context\" key me convert karke doc_chain ko feed karta hai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b14dff",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
